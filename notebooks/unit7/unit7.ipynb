{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linqus/RL-huggingface/blob/main/notebooks/unit7/unit7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8sh1afGLsyBl",
        "outputId": "7e618948-b106-466f-d565-ec9e6bd7ca9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ml-agents'...\n",
            "remote: Enumerating objects: 2386, done.\u001b[K\n",
            "remote: Counting objects: 100% (2386/2386), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1916/1916), done.\u001b[K\n",
            "remote: Total 2386 (delta 911), reused 1335 (delta 451), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2386/2386), 97.65 MiB | 11.36 MiB/s, done.\n",
            "Resolving deltas: 100% (911/911), done.\n",
            "Updating files: 100% (2215/2215), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --depth 1 https://github.com/Unity-Technologies/ml-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Go inside the repository and install the package\n",
        "%cd ml-agents\n",
        "!pip3 install -e ./ml-agents-envs\n",
        "!pip3 install -e ./ml-agents"
      ],
      "metadata": {
        "id": "0f16xIJr8Lxn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Here, we create training-envs-executables and linux\n",
        "!mkdir ./training-envs-executables\n",
        "!mkdir ./training-envs-executables/linux"
      ],
      "metadata": {
        "id": "LCrOXaH67J_i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL\" -O ./training-envs-executables/linux/SoccerTwos.zip && rm -rf /tmp/cookies.txt\n"
      ],
      "metadata": {
        "id": "QRl0wDsr7PZh",
        "outputId": "2dfc5bc4-7207-4dc0-9712-1a443491a69e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-05 17:13:27--  https://docs.google.com/uc?export=download&confirm=t&id=1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.12.100, 142.251.12.139, 142.251.12.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.12.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-8c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0ob7crg5vsbff3uc2i4ud3hjcu270dl6/1701796350000/09764732090272539193/*/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL?e=download&uuid=ccf1328c-dcbc-45ae-94bf-cd7377355eec [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-12-05 17:13:28--  https://doc-04-8c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0ob7crg5vsbff3uc2i4ud3hjcu270dl6/1701796350000/09764732090272539193/*/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL?e=download&uuid=ccf1328c-dcbc-45ae-94bf-cd7377355eec\n",
            "Resolving doc-04-8c-docs.googleusercontent.com (doc-04-8c-docs.googleusercontent.com)... 74.125.24.132, 2404:6800:4003:c03::84\n",
            "Connecting to doc-04-8c-docs.googleusercontent.com (doc-04-8c-docs.googleusercontent.com)|74.125.24.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36963480 (35M) [application/x-zip-compressed]\n",
            "Saving to: ‘./training-envs-executables/linux/SoccerTwos.zip’\n",
            "\n",
            "./training-envs-exe 100%[===================>]  35.25M   187MB/s    in 0.2s    \n",
            "\n",
            "2023-12-05 17:13:28 (187 MB/s) - ‘./training-envs-executables/linux/SoccerTwos.zip’ saved [36963480/36963480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://drive.google.com/file/d/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL/view?usp=sharing"
      ],
      "metadata": {
        "id": "s0spCTOJ7a5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%capture\n",
        "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/SoccerTwos.zip"
      ],
      "metadata": {
        "id": "5KjFvUEj7xjv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod -R 755 ./training-envs-executables/linux/SoccerTwos.x86_64"
      ],
      "metadata": {
        "id": "dsL0JXM58aXj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The config file we’re going to use here is in ./config/poca/SoccerTwos.yaml. It looks like this:"
      ],
      "metadata": {
        "id": "WQdNea3v-QHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "behaviors:\n",
        "  SoccerTwos:\n",
        "    trainer_type: poca\n",
        "    hyperparameters:\n",
        "      batch_size: 2048\n",
        "      buffer_size: 20480\n",
        "      learning_rate: 0.0003\n",
        "      beta: 0.005\n",
        "      epsilon: 0.2\n",
        "      lambd: 0.95\n",
        "      num_epoch: 3\n",
        "      learning_rate_schedule: constant\n",
        "    network_settings:\n",
        "      normalize: false\n",
        "      hidden_units: 512\n",
        "      num_layers: 2\n",
        "      vis_encode_type: simple\n",
        "    reward_signals:\n",
        "      extrinsic:\n",
        "        gamma: 0.99\n",
        "        strength: 1.0\n",
        "    keep_checkpoints: 5\n",
        "    max_steps: 5000000\n",
        "    time_horizon: 1000\n",
        "    summary_freq: 10000\n",
        "    self_play:\n",
        "      save_steps: 50000\n",
        "      team_change: 200000\n",
        "      swap_steps: 2000\n",
        "      window: 10\n",
        "      play_against_latest_model_ratio: 0.5\n",
        "      initial_elo: 1200.0"
      ],
      "metadata": {
        "id": "nNZhR30x9SpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-learn ./config/poca/SoccerTwos.yaml --env=./training-envs-executables/linux/SoccerTwos.x86_64 --run-id=\"SoccerTwos\" --no-graphics --force"
      ],
      "metadata": {
        "id": "KixSPlAU94XA",
        "outputId": "a6d81fea-a0b2-4cdb-ae8d-34266eec03cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "2023-12-05 17:17:19.679020: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-05 17:17:19.679079: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-05 17:17:19.679113: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-05 17:17:19.686515: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "            ┐  ╖\n",
            "        ╓╖╬│╡  ││╬╖╖\n",
            "    ╓╖╬│││││┘  ╬│││││╬╖\n",
            " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
            " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
            " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
            " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
            " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
            " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
            " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
            "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
            "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
            "          ╙╬╬╬╣╣╣╜\n",
            "             ╙\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 1.1.0.dev0,\n",
            "  ml-agents-envs: 1.1.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 2.1.1+cu121\n",
            "[INFO] Connected to Unity environment with package version 2.3.0-exp.3 and communication version 1.5.0\n",
            "[INFO] Connected new brain: SoccerTwos?team=1\n",
            "[INFO] Connected new brain: SoccerTwos?team=0\n",
            "[INFO] Hyperparameters for behavior name SoccerTwos: \n",
            "\ttrainer_type:\tpoca\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t2048\n",
            "\t  buffer_size:\t20480\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  learning_rate_schedule:\tconstant\n",
            "\t  beta_schedule:\tconstant\n",
            "\t  epsilon_schedule:\tconstant\n",
            "\tcheckpoint_interval:\t500000\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t2\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t5\n",
            "\teven_checkpoints:\tFalse\n",
            "\tmax_steps:\t5000000\n",
            "\ttime_horizon:\t1000\n",
            "\tsummary_freq:\t10000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\t\n",
            "\t  save_steps:\t50000\n",
            "\t  team_change:\t200000\n",
            "\t  swap_steps:\t2000\n",
            "\t  window:\t10\n",
            "\t  play_against_latest_model_ratio:\t0.5\n",
            "\t  initial_elo:\t1200.0\n",
            "\tbehavioral_cloning:\tNone\n",
            "/content/ml-agents/ml-agents/mlagents/trainers/torch_entities/utils.py:289: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3614.)\n",
            "  torch.nn.functional.one_hot(_act.T, action_size[i]).float()\n",
            "[INFO] SoccerTwos. Step: 10000. Time Elapsed: 37.811 s. Mean Reward: 0.000. Mean Group Reward: -0.183. Training. ELO: 1200.080.\n",
            "[INFO] SoccerTwos. Step: 20000. Time Elapsed: 60.149 s. Mean Reward: 0.000. Mean Group Reward: -0.242. Training. ELO: 1198.996.\n",
            "[INFO] SoccerTwos. Step: 30000. Time Elapsed: 84.129 s. Mean Reward: 0.000. Mean Group Reward: 0.072. Training. ELO: 1200.249.\n",
            "[INFO] SoccerTwos. Step: 40000. Time Elapsed: 105.525 s. Mean Reward: 0.000. Mean Group Reward: -0.018. Training. ELO: 1200.999.\n",
            "[INFO] SoccerTwos. Step: 50000. Time Elapsed: 132.706 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1200.245.\n",
            "[INFO] SoccerTwos. Step: 60000. Time Elapsed: 156.644 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 70000. Time Elapsed: 180.784 s. Mean Reward: 0.000. Mean Group Reward: 0.006. Training. ELO: 1200.744.\n",
            "[INFO] SoccerTwos. Step: 80000. Time Elapsed: 200.432 s. Mean Reward: 0.000. Mean Group Reward: -0.142. Training. ELO: 1200.492.\n",
            "[INFO] SoccerTwos. Step: 90000. Time Elapsed: 226.059 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1200.239.\n",
            "[INFO] SoccerTwos. Step: 100000. Time Elapsed: 245.811 s. Mean Reward: 0.000. Mean Group Reward: -0.095. Training. ELO: 1199.115.\n",
            "[INFO] SoccerTwos. Step: 110000. Time Elapsed: 271.479 s. Mean Reward: 0.000. Mean Group Reward: 0.112. Training. ELO: 1200.302.\n",
            "[INFO] SoccerTwos. Step: 120000. Time Elapsed: 293.716 s. Mean Reward: 0.000. Mean Group Reward: -0.034. Training. ELO: 1202.459.\n",
            "[INFO] SoccerTwos. Step: 130000. Time Elapsed: 313.128 s. Mean Reward: 0.000. Mean Group Reward: -0.273. Training. ELO: 1201.067.\n",
            "[INFO] SoccerTwos. Step: 140000. Time Elapsed: 340.787 s. Mean Reward: 0.000. Mean Group Reward: -0.273. Training. ELO: 1200.193.\n",
            "[INFO] SoccerTwos. Step: 150000. Time Elapsed: 361.570 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1199.943.\n",
            "[INFO] SoccerTwos. Step: 160000. Time Elapsed: 377.328 s. Mean Reward: 0.000. Mean Group Reward: -0.112. Training. ELO: 1199.943.\n",
            "[INFO] SoccerTwos. Step: 170000. Time Elapsed: 401.604 s. Mean Reward: 0.000. Mean Group Reward: 0.092. Training. ELO: 1201.820.\n",
            "[INFO] SoccerTwos. Step: 180000. Time Elapsed: 431.598 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 190000. Time Elapsed: 446.668 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 200000. Time Elapsed: 472.524 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 210000. Time Elapsed: 507.180 s. Mean Reward: 0.000. Mean Group Reward: -0.232. Training. ELO: 1201.664.\n",
            "[INFO] SoccerTwos. Step: 220000. Time Elapsed: 532.604 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1201.155.\n",
            "[INFO] SoccerTwos. Step: 230000. Time Elapsed: 546.582 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 240000. Time Elapsed: 576.765 s. Mean Reward: 0.000. Mean Group Reward: 0.168. Training. ELO: 1200.901.\n",
            "[INFO] SoccerTwos. Step: 250000. Time Elapsed: 593.405 s. Mean Reward: 0.000. Mean Group Reward: -0.072. Training. ELO: 1201.777.\n",
            "[INFO] SoccerTwos. Step: 260000. Time Elapsed: 619.221 s. Mean Reward: 0.000. Mean Group Reward: -0.250. Training. ELO: 1201.149.\n",
            "[INFO] SoccerTwos. Step: 270000. Time Elapsed: 638.556 s. Mean Reward: 0.000. Mean Group Reward: -0.173. Training. ELO: 1200.649.\n",
            "[INFO] SoccerTwos. Step: 280000. Time Elapsed: 663.021 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1199.903.\n",
            "[INFO] SoccerTwos. Step: 290000. Time Elapsed: 688.329 s. Mean Reward: 0.000. Mean Group Reward: 0.056. Training. ELO: 1199.903.\n",
            "[INFO] SoccerTwos. Step: 300000. Time Elapsed: 708.059 s. Mean Reward: 0.000. Mean Group Reward: 0.018. Training. ELO: 1200.652.\n",
            "[INFO] SoccerTwos. Step: 310000. Time Elapsed: 727.641 s. Mean Reward: 0.000. Mean Group Reward: -0.265. Training. ELO: 1199.583.\n",
            "[INFO] SoccerTwos. Step: 320000. Time Elapsed: 757.105 s. Mean Reward: 0.000. Mean Group Reward: -0.388. Training. ELO: 1197.332.\n",
            "[INFO] SoccerTwos. Step: 330000. Time Elapsed: 776.160 s. Mean Reward: 0.000. Mean Group Reward: 0.012. Training. ELO: 1197.694.\n",
            "[INFO] SoccerTwos. Step: 340000. Time Elapsed: 791.238 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 350000. Time Elapsed: 819.229 s. Mean Reward: 0.000. Mean Group Reward: -0.140. Training. ELO: 1197.465.\n",
            "[INFO] SoccerTwos. Step: 360000. Time Elapsed: 845.112 s. Mean Reward: 0.000. Mean Group Reward: -0.426. Training. ELO: 1196.234.\n",
            "[INFO] SoccerTwos. Step: 370000. Time Elapsed: 862.225 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 380000. Time Elapsed: 887.314 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1194.269.\n",
            "[INFO] SoccerTwos. Step: 390000. Time Elapsed: 905.514 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 400000. Time Elapsed: 928.993 s. Mean Reward: 0.000. Mean Group Reward: 0.113. Training. ELO: 1194.916.\n",
            "[INFO] SoccerTwos. Step: 410000. Time Elapsed: 961.731 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1194.860.\n",
            "[INFO] SoccerTwos. Step: 420000. Time Elapsed: 984.459 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1193.330.\n",
            "[INFO] SoccerTwos. Step: 430000. Time Elapsed: 1012.541 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 440000. Time Elapsed: 1028.877 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 450000. Time Elapsed: 1054.732 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 460000. Time Elapsed: 1077.271 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 470000. Time Elapsed: 1094.583 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1192.336.\n",
            "[INFO] SoccerTwos. Step: 480000. Time Elapsed: 1124.744 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 490000. Time Elapsed: 1138.756 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 500000. Time Elapsed: 1162.283 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1192.087.\n",
            "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-499062.onnx\n",
            "[INFO] SoccerTwos. Step: 510000. Time Elapsed: 1185.593 s. Mean Reward: 0.000. Mean Group Reward: 0.120. Training. ELO: 1192.087.\n",
            "[INFO] SoccerTwos. Step: 520000. Time Elapsed: 1211.563 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 530000. Time Elapsed: 1231.107 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 540000. Time Elapsed: 1259.499 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1192.087.\n",
            "[INFO] SoccerTwos. Step: 550000. Time Elapsed: 1277.886 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 560000. Time Elapsed: 1302.405 s. Mean Reward: 0.000. Mean Group Reward: 0.068. Training. ELO: 1192.087.\n",
            "[INFO] SoccerTwos. Step: 570000. Time Elapsed: 1325.990 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 580000. Time Elapsed: 1345.181 s. Mean Reward: 0.000. Mean Group Reward: 0.106. Training. ELO: 1192.930.\n",
            "[INFO] SoccerTwos. Step: 590000. Time Elapsed: 1368.427 s. Mean Reward: 0.000. Mean Group Reward: 0.038. Training.\n",
            "[INFO] SoccerTwos. Step: 600000. Time Elapsed: 1394.737 s. Mean Reward: 0.000. Mean Group Reward: -0.100. Training. ELO: 1193.378.\n",
            "[INFO] SoccerTwos. Step: 610000. Time Elapsed: 1426.297 s. Mean Reward: 0.000. Mean Group Reward: -0.076. Training. ELO: 1194.093.\n",
            "[INFO] SoccerTwos. Step: 620000. Time Elapsed: 1446.136 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 630000. Time Elapsed: 1465.640 s. Mean Reward: 0.000. Mean Group Reward: 0.012. Training. ELO: 1194.909.\n",
            "[INFO] SoccerTwos. Step: 640000. Time Elapsed: 1490.495 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 650000. Time Elapsed: 1518.636 s. Mean Reward: 0.000. Mean Group Reward: -0.100. Training. ELO: 1194.408.\n",
            "[INFO] SoccerTwos. Step: 660000. Time Elapsed: 1533.939 s. Mean Reward: 0.000. Mean Group Reward: -0.100. Training.\n",
            "[INFO] SoccerTwos. Step: 670000. Time Elapsed: 1564.920 s. Mean Reward: 0.000. Mean Group Reward: 0.094. Training. ELO: 1194.157.\n",
            "[INFO] SoccerTwos. Step: 680000. Time Elapsed: 1580.490 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 690000. Time Elapsed: 1608.331 s. Mean Reward: 0.000. Mean Group Reward: -0.208. Training. ELO: 1194.157.\n",
            "[INFO] SoccerTwos. Step: 700000. Time Elapsed: 1625.333 s. Mean Reward: 0.000. Mean Group Reward: 0.266. Training. ELO: 1194.157.\n",
            "[INFO] SoccerTwos. Step: 710000. Time Elapsed: 1652.644 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1194.157.\n",
            "[INFO] SoccerTwos. Step: 720000. Time Elapsed: 1675.975 s. Mean Reward: 0.000. Mean Group Reward: 0.042. Training. ELO: 1194.908.\n",
            "[INFO] SoccerTwos. Step: 730000. Time Elapsed: 1694.954 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 740000. Time Elapsed: 1719.404 s. Mean Reward: 0.000. Mean Group Reward: 0.066. Training. ELO: 1196.895.\n",
            "[INFO] SoccerTwos. Step: 750000. Time Elapsed: 1746.896 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 760000. Time Elapsed: 1764.109 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 770000. Time Elapsed: 1793.331 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1197.370.\n",
            "[INFO] SoccerTwos. Step: 780000. Time Elapsed: 1804.444 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 790000. Time Elapsed: 1831.520 s. Mean Reward: 0.000. Mean Group Reward: -0.009. Training. ELO: 1196.780.\n",
            "[INFO] SoccerTwos. Step: 800000. Time Elapsed: 1860.081 s. Mean Reward: 0.000. Mean Group Reward: 0.063. Training. ELO: 1197.111.\n",
            "[INFO] SoccerTwos. Step: 810000. Time Elapsed: 1890.508 s. Mean Reward: 0.000. Mean Group Reward: -0.105. Training. ELO: 1196.353.\n",
            "[INFO] SoccerTwos. Step: 820000. Time Elapsed: 1908.987 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 830000. Time Elapsed: 1939.789 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1196.101.\n",
            "[INFO] SoccerTwos. Step: 840000. Time Elapsed: 1966.200 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 850000. Time Elapsed: 1979.040 s. Mean Reward: 0.000. Mean Group Reward: 0.079. Training. ELO: 1196.101.\n",
            "[INFO] SoccerTwos. Step: 860000. Time Elapsed: 2012.767 s. Mean Reward: 0.000. Mean Group Reward: -0.308. Training. ELO: 1195.723.\n",
            "[INFO] SoccerTwos. Step: 870000. Time Elapsed: 2024.064 s. Mean Reward: 0.000. Mean Group Reward: 0.172. Training. ELO: 1195.841.\n",
            "[INFO] SoccerTwos. Step: 880000. Time Elapsed: 2055.784 s. Mean Reward: 0.000. Mean Group Reward: 0.155. Training. ELO: 1196.832.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "NzCrEaQY_c28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-push-to-hf  --run-id=\"SoccerTwos\" --local-dir=\"./results/SoccerTwos\" --repo-id=\"linqus/poca-SoccerTwos\" --commit-message=\"First Push\""
      ],
      "metadata": {
        "id": "yj_c5t8G_V7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}